# RCNN ; CNN-LSTM Model (Chapter 12)

Assign: Anonymous
Due Date: December 12, 2021
Status: Completed

# Introduction

**동영상**

- 초당 30장 정도의 프레임 이미지로 구성(30fps)되는 대표적인 ***시계열 데이터***
- i.e. 이미지를 시간대별 데이터로 하는 시계열 데이터
- 동영상 학습을 위해, 이미지 데이터를 처리하는 CNN 과 시계열 데이터를 처리하는 RNN 의 기능 결합 필요
- 동영상 데이터는 5차원 데이터로 처리
    - [미니배치, 시간(프레임 번호), 이미지행, 이미지열, 채널] > 파이토치랑 텐서가 순서가 다르다?

<img width="365" alt="스크린샷_2021-12-05_오후_1 44 49" src="https://user-images.githubusercontent.com/54128055/147530876-fc632f2a-11fd-4e25-ab51-10ac0017a782.png">

**주의! 시계열 데이터는 각 데이터의 첫 값에 데이터의 길이 저장 & 첫 시간대의 다른 차원 값에는 의미없는 값**

→ 시계열 데이터는 RNN 처리에 알맞게 확장된 데이터 형식을 갖고 있기 때문에 CNN 으로 처리 불가능

→ 시계열 포장 계층 ; sequential wrapping layer ; seqwrap (복합 계층) 추가

- 내부에 서브 신경망을 가지면서 외부에 하나의 계층인 것처럼 인터페이스 제공
- 외부의 인접 계층들에 대해 시계열 데이터를 입력으로 받아, 시계열 데이터 형태의 출력을 생성
- 내부적으로는 시계열 데이터의 포장을 풀어 비순환 계층들의 서브 신경망을 이용해 각 시간대별 데이터 처리

***시계열 포장 계층 아이디어는 다양한 데이터 형식에 대해 유연한 대처가 가능하도록 프로그램을 확장하는데 유용***

# Sequential Wrapping Layer

**신경망 구성 및 각 계층 입출력 데이터 형태 표기**

<img width="223" alt="스크린샷_2021-12-05_오후_1 58 44" src="https://user-images.githubusercontent.com/54128055/147530880-7d81326f-6022-4eab-9caa-a6b050301fee.png">

- 최초 입력 [10, 101, 90, 120, 3] ([미니배치, 시간, 이미지 행, 이미지 열, 채널])
- 101은 시계열 데이터의 최대 길이 100에 길이 정보 1을 더한 값
- 원본 해상도는 1,440 x 1,080 이어서, 전처리 작업으로 가로 세로 1/12 로 줄임

<img width="380" alt="스크린샷_2021-12-05_오후_3 40 38" src="https://user-images.githubusercontent.com/54128055/147530881-36eec9f0-cca9-4207-ae18-7c5b2e091356.png">

- 전체적인 신경망 구조 : (seqwrap 계층 + lstm 계층 = )은닉 계층 + 출력계층
- seqwrap 계층은 미니배치 축과 시간대 축을 묶어 변형된 미니배치 데이터로 변형
    - [10, 101, 90, 120, 3] → [1000, 90, 120, 3] (길이 정보는 따로 보존, 배치 처리에서 배제)
- 서브 신경망의 출력으로 [1000, 12] 형태의 출력이 생성되면, [10, 101, 12] 형태의 시계열로 다시 변환

## 12.3 출력층, 후처리 단계에서 시계열 데이터 처리

코드내용 skip

# 장면 전환 데이터셋

장면전환 : 인접한 프레임 사이에서 이미지 내용이 크게 바뀌는 현상 (0번 프레임 포함)

<img width="395" alt="스크린샷_2021-12-05_오후_7 02 35" src="https://user-images.githubusercontent.com/54128055/147530883-887e2ca3-17c4-4cc0-a869-23e9630faa87.png">

- 위 사진에서 6-7, 10-11, 13-14 프레임 사이에서 장면 전환 발생
- 18 프레임으로 구성된 영상 데이터를 시계열 데이터로 저장하려면 길이 정보를 포함해 19칸의 공간 필요
- 각 칸에는 3차원 이미지 내용이 담아서 시계열 차원까지 4차원 데이터 (+ 미니배치 포함 5차원)

*장면 전환에 대해 신경망을 학습하고 결과를 평가하기 위해 labeled data 필요*

## Labeled Data

<img width="400" alt="스크린샷_2021-12-06_오후_3 23 29" src="https://user-images.githubusercontent.com/54128055/147530884-894ccbab-7a08-46cb-897c-39a05e643bb2.png">


- 장면전환 여부를 나타내는 이진값 사용
- 시간, 장면 전환 여부, 미니배치 정보를 담는 3차원 데이터 (첫 값에 데이터의 길이 정보)
- 장면 전환이 일어나는 경계 프레임 중 뒤에 위치하는 프레임에 장면 전환 이진값 부여

***영상 데이터에서 장면 전환이 일어나는 프레임은 극히 일부***

e.g. 예시로 사용한 '스타탄생' 영화의 경우 전체 15만 개 프레임 중 600개 장면전환 발생 (0.4%)

### Labeled Data 구성

1. 임의의 영상 데이터에서 임의 위치의 프레임 선택 후 연속된 일부 프레임 선택
2. 1번 과정에서 선택한 연속된 프레임 사이에는 장면 전환이 없다고 간주
3. 1, 2번 과정을 반복진행, 1번 과정에서 또 다른 임의의 위치로 이동할 때 장면 전환 발생 간주
4. 선택된 프레임이 새로운 프레임 묶음의 시작인지 여부에 따라 이진값 부여

***오류 발생 가능성이 있지만, 장면 전환은 영상 데이터에서 차지하는 비율이 적기 때문에 감안하고 데이터 구성***
