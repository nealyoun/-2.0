# 1. Single Layer Perceptron

# 1.1 퍼셉트론 신경망 구조

- 단층 퍼셉트론 경우 입력벡터(input layer), 출력벡터(output layer)으로 구성되며,

    각 입력벡터(x1~xi)는 가중치 벡터와 편향값 (bias, xo*wo)을 이용하여 결합함수(시그마), 활성함수 (임계함수)를 거쳐 출력 벡터를 뱉는 구조



- 식으로 보면 z = w1*x1 + w2*x2 + ... wn * xn 까지가 결합 함수 (회귀식과 동일)
- 결합 함수를 Activation Function(임계함수)을 거쳐 출력한다.
- (계단식 함수라면) z(net) 값이 임계치를 넘냐 안넘냐 에 따라 0,1 호출
*Q : 바이너리 문제가 아닌 회귀 문제라면 활성화 함수는 어떤게 들어가나??*


# 1.2 텐서 연산과 미니배치의 활용

- **텐서란?** 
텐서를 엄밀하게 정의하기란 쉽지는 않지만 딥러닝에서는 다차원 숫자 배열이라고 이해해도 무리 없음
e.g. 0차원 스칼라, 1차원 벡터, 2차원 행렬 모두 텐서 3차원도 물론 텐서
- **텐서가 중요한 이유는?**
같은 문제라도 텐서를 이용해 처리하는 편이 프로그램 최적화 및 처리 속도도 훨씬 빠르다고 한다.
인터프리터 자체가 반복문 보다 텐서 연산을 효율적으로 처리 (GPU 환경에서는 더더욱!)
Q : 반복문보다 효율적으로 처리하는건 알겠는데 텐서의 연산 방식이 멀까??
→ 벡터 내적 연산으로 x*w 단번의 계산하는 편이 간단
(같은 위치에 곱의 합)

- **미니배치란?**
일반적으로 딥러닝에서는 여러 데이터를 한꺼번에 처리하는데 이를 미니배치라고 한다.
(그냥 n수의 데이터를 신경망 계산을 하는 것을 미니 배치라고 하는 듯 ?)
이미지 같은 경우 데이터가 커서 배치 단위로 나누어서 돌린다. (2^n 단위)

- **단층 퍼셉트론 (SLP)의 동작 방식 (입력층 → 출력층)**  
아래 그림을 보면 
(a) 는 퍼셉트론 하나의 동작 방식 —> 1개의 퍼셉트론 1 동그라미 x1*w1+x2*w..x4*w4 + b = y1
(b) 는 SLP를 구성하는 일련의 퍼셉트론(여러 동그라미) 즉 1개의 o1이 데이터를 1개 처리하는 방식 
가중치 벡터는 퍼셉트론의 수만큼 가중치 행렬 W가 되고 출력 벡터 (yi 값)
yi = x1*w1i + .. + xn*win + bi로 계산되고 한꺼번에 y = xW+b로 표현 (행렬 연산 상태로 한번에 계산) 
****(c) 그림은 (b) 그림을 n개의 데이터를 처리

여기서 학습데이터를 n개만큼 1번 처리하면 1**epoch**(에폭)
반복 수에는 고려되지 않으나 신경망 구조나 학습 결과에 영향을 미치는 고려요인은 **하이퍼파라미터**라고 한다
(e.g. 러닝레이트)


- 학습
결국에는 퍼셉트론 학습이란 최상의 결과를 도출하는 연결강도 (세타값, 가중치)를 찾는 것으로 볼 수 있는데,
case updating 방식을 사용하게 된다.
 

# 1.3 신경망의 세 가지 기본 출력 유형과 회귀 분석

알고리즘은 세분화하면 회귀, 이진 분류, 선택 분류(multi class)



# 1.5 회귀 분석과 평균제곱오차(MSE) 손실 함수

회귀분석에서 실제값 y을 예측값이 얼마나 정확한지 판단하는 것을 MSE로 평가지표로 삼는다.

딥러닝에서는 값이 항상 0이상이며, 추정이 정확해질 수록 값이 작아지는 성질이 있으면서 미분도 가능한 평가지표를 정의한 후 이를 최소화하는 것을 목표로 학습을 수행한다. **이를 손실 함수(loss function), 비용 함수(cost function)이 라고한다.** 

# 1.6 경사하강법과 역전파

경사하강법 (gradient descent algorithm)은 함수의 기울기를 반복 계산하면서 이 기울기에 따라 함숫값이 낮아지는 방향으로 이동하는 기본적인 딥러닝 학습 알고리즘 (함수값이 낮아지는 값을 확인)

딥러닝은 기본적으로 가변 파라미터를 갖는 신경망 구조를 설정한 후  학습을 통해 파라미터(가중치, 편향) 값들을 조절하여 신경망이 원하는 동작을 수행하도록 만드는 인공지능 기법 

경사하강법은 순전파와 역전파 과정을 번갈아 수행하는 과정을 반복하면서 신경망 파라미터(가중치,편향)을 원하는 값으로 바꾸어 나간다.

**순전파**란 입력 데이터에 대해 신경망 구조를 따라가면서 현재의 파라미터값들을 이용해 손실 함숫값을 계산하는 과정을 말한다. 

**역전파**란 순전파의 계산 과정을 역순으로 거슬러가면서 손실 함숫값에 직간접적으로 영향을 미친 모든 성분에 대하여 손실 기울기를 계산하는 과정


**batch size는 한 번의 batch마다 주는 데이터 샘플의 size. 여기서 batch(보통 mini-batch라고 표현)는 나눠진 데이터 셋을 뜻하며 iteration는 epoch를 나누어서 실행하는 횟수라고 생각하면 됨.**

**메모리의 한계와 속도 저하 때문에 대부분의 경우에는 한 번의 epoch에서 모든 데이터를 한꺼번에 집어넣을 수는 없습니다. 그래서 데이터를 나누어서 주게 되는데 이때 몇 번 나누어서 주는가를 iteration, 각 iteration마다 주는 데이터 사이즈를 batch size라고 합니다.**




