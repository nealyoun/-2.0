# Simple Convolution Model (chapter7)

Assign: Anonymous
Due Date: October 31, 2021
Status: Completed

합성곱 신경망은 이미지 처리에 맞게 다층 퍼셉트론을 변형시킨 신경망으로 흔히 CNN (Convolution Neural Network) 라 부른다.

CNN은 이미지 처리에 맞게 고안된 합성곱 계층과 풀링 계층이 새로운 유형의 은닉 계층으로 이용되며,
완전 연결 계층(fully connected layer)에 비해 획기적으로 줄어든 수의 파라미터만을 가지며, 풀링 계층은 아예 파라미터를 갖지 않음

## 7.1 다층 퍼셉트론의 문제점과 새로운 구조의 필요성

다층 퍼셉트론 신경망은 입력과 출력 계층 사이 은닉 계층을 가지며, 계층 간의 연결은 양쪽 계층의 모든 퍼셉트론 쌍이 빠짐없이 연결되는 방식의 이유로 신경망의 은닉 계층을 완전 연결 계층(fully connected layer)라고 부른다.

![Untitled](Simple%20Convolution%20Model%20(chapter7)%201a47b3ce1d1e489bb4d4a2be0426b495/Untitled.png)

이러한 신경망의 경우, 
1. 이미지 전체를 하나의 데이터로 입력하기 때문에 이미지 특성을 찾지 못하고 이미지 위치가 약간 변경되거나 왜곡 된경우 올바른 성능 X → 데이터 형상 무시됨
2. 많은 수의 픽셀로 구성된 경우 입력 벡터 크기가 커지면서 가중치 파라미터가 엄청난 크기 값을 가지게 되어 학습 부하, 많은양 데이터 필요 등 
3. 오버피팅

이러한 다층 퍼셉트론의 문제의식으로 출발한 CNN의 구조는 합성곱 계층에 있는 커널(필터)라는 작은 가중치 텐서를 이미지 모든 영역에 반복 적용해 패턴을 찾음 (마스크 연산)
+ 풀링 계층을 이용하여 이미지 해상도를 줄이는 기능을 제공해 다양한 크기의 패턴을 단계적으로 처리할 수 있게한다. 

CNN은 이미지를 하나의 데이터가 아닌, 여러개로 분할하여 처리하여 이미지가 왜곡되더라도 이미지의 부분적 특성을 추출할 수 있어 올바른 성능을 낼 수 있고 신경망 파라미터 수를 획기적으로 줄이면서도 각 구성 요소의 전문성을 높여 품질을 향상한다. 
(Feature Learning + Classification)

![Untitled](Simple%20Convolution%20Model%20(chapter7)%201a47b3ce1d1e489bb4d4a2be0426b495/Untitled%201.png)

## 7.2 합성곱 계층

CNN은 합성곱이라는 수학 연산에 힌트를 얻어 고안된 처리 방식을 이용하는 은닉 계층

![Untitled](Simple%20Convolution%20Model%20(chapter7)%201a47b3ce1d1e489bb4d4a2be0426b495/Untitled%202.png)

커널(필터)라는 작은 텐서의 가중치 파라미터를 이용하여 입력 픽셀 값들로부터 출력 픽셀값을 계산한다.(다층 퍼셉트론은 출력 픽셀 하나하나가 각각 입력 픽셀 전체로부터 계산)

합성곱 연산은 커널 크기만큼의 크기를 가지며 중심 위치는 계산할 출력 픽셀의 위치이어야 하고 이 그림에서처럼 입력 픽셀값들과 커널의 가중치들을 짝지어 곱한 후 커널의 편향값과 합산해 구한다. (커널 편향 (1,1)) 

위 그림 6X6 형태의 입력 픽셀 값이라면 fully connected layer로 보았을 때, 
전체 파라미터 수 36X36+36 = 1,332개
합성곱 연산은 3X3+1 = 10개 임 (stride = 1)  

커널(채널)을 이용한 처리는 파라미터 수를 줄여 메모리 부담을 줄여주는 동시에 다음과 같은 두 가지 장점도 있음

1. 커널의 반복 이용으로 커널에 대한 학습 횟수가 늘어나는 효과가 생겨 학습 빠름
2. 같은 커널이 모든 위치에 적용되어 한 곳에서 포착된 패턴이 다른 곳에 이용 가능

## 7.3 합성곱 연산의 패딩과 건너뛰기

합성곱 계층에서 출력 픽셀값을 계산하려고 입력 영역을 커널 크기로 확장시키다 보면 경계 부근에서는 확장영역이 실제 입력 범위를 벗어날 수 있다. 
또 합성곱이 반복되다보면 출력 픽셀이 계속 줄어든다. 이러한 문제를 해결하는 방법을
패딩(padding)이라고 함 

패딩은 SAME, VALID 방식이 있음

- SAME 패딩 (zero 패딩)

![Untitled](Simple%20Convolution%20Model%20(chapter7)%201a47b3ce1d1e489bb4d4a2be0426b495/Untitled%203.png)

SAME 패딩 방식은 출력 픽셀 계산에 문제가 없도록 전체 입력 행렬 주위를 0으로 둘러싸 확장한다.
커널 중심 위치가 가장자리에 올 때 문제가 생길 수 있음

- Valid 패딩

![Untitled](Simple%20Convolution%20Model%20(chapter7)%201a47b3ce1d1e489bb4d4a2be0426b495/Untitled%204.png)

VALID 패딩 방식은 커널이 실제 입력 범위를 벗어나지 않을 때만 출력 픽셀을 생성한다.
6X6 크기 입력이 4X4 크기로 줄어들게 된다. 
but 입출력 형태가 똑같이 유지되는 편이 신경망 구조를 설계하기 쉽고 반복 적용에도 유리하기 때문에 SAME 패딩 방식이 더 널리 이용됨

- 건너뛰기 (stride)
합성곱 계층에서 출력을 생성할 때 일정한 간격으로 건너 뛰면서 픽셀을 만들 수 있음
건너뛰는 정도를 지정하는 값을 건너뛰기 보폭 혹은 보폭(stride)라고 한다.

![Untitled](Simple%20Convolution%20Model%20(chapter7)%201a47b3ce1d1e489bb4d4a2be0426b495/Untitled%205.png)

위 그림처럼 가로세로 보폭을 [2,3]으로 지정한다면 3X2 출력이 만들어짐
다음 단계 처리 부담을 줄여주지만 많은 정보를 무시해버리는 단점이 있음
풀링 계층은 이미지 축소 효과를 가지면서도 픽셀의 정보를 이렇게 일방적으로 무시하지 않음 so stride 보다는 풀링 계층이 더 널리 이용됨

## 7.4 풀링 계층(sub sampling)

풀링은 아래 그림처럼 일정 영역(커널 크기)의 입력 픽셀값들로부터 그 최대치나 평균치 같은 대푯값을 구해 출력 픽셀로 생성하는 처리를 말한다.  (필터링된 이미지 크기를 줄일 수 있도록)

![Untitled](Simple%20Convolution%20Model%20(chapter7)%201a47b3ce1d1e489bb4d4a2be0426b495/Untitled%206.png)

평균값의 경우 모든 입력 픽셀 값이 출력에 반영되지만 최댓값은 직접 반영되지 않는 입력 픽셀이 생긴다. but 건너뛰기 처리 때 처럼 일방적으로 무시당한다고는 볼 수 없다.
(최댓 값을 뽑는 과정에서 비교 대상이 되어 출력에 간접적으로나마 영향을 미치기 때문)

- 풀링 계층에서 이미지 크기, 커널 크기, 보폭 관계

![Untitled](Simple%20Convolution%20Model%20(chapter7)%201a47b3ce1d1e489bb4d4a2be0426b495/Untitled%207.png)

(a) 커널 크기와, 보폭이 서로 다름 
- 입력 영역들이 서로 겹치거나 비는 영역이 생기면서 처리가 불편함
모든 입력이 픽셀 위치에 대응하는 출력 픽셀들을 구한 후 건너뛰기 처리로 걸러내 최종 결과를 생성하는 것 

(b) 커널 크기와 보폭이 모두 4 X 4로 동일
- 이런 경우 입력 픽셀들을 처음부터 이 크기로 분할한 후 분할된 영역에서 대표값을 뽑아 곧바로 출력 픽셀을 뽑을 수 있어서 효율적인 처리 가능
but 가장자리 부분에서 분할 영역이 입력 범위를 벗어나는 경우가 있음
(c) 커널 크기 보폭 동일, 이미지 크기가 보폭의 배수
이런 경우 입력 픽셀들을 자투리 없이 깨끗하게 분할할 수 있어서 간단하고 효율적인 처리

풀링 연산은 입력만으로 대푯값을 구하는 과정이기 때문에 파라미터가 따로 필요 없음 

(역전파, 순전파 처리 빠르다. → 파라미터가 없어서 학습으로 성능이 개선되지는 않는다.)
그럼에도 풀링 계층은 매우 유용한데 보통 합성곱 계층 사이에 배치되어 점점 작은 해상도의 특징맵에 정보가 집약되게 만드는데 이용